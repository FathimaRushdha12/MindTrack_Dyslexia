<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>More Info</title>
  <link href="https://fonts.googleapis.com/css?family=Montserrat:300,400,700&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="styles.css" />

</head>
<body>


<header id="header">
  <div class="nav-bar">
    <div class="hamburger">☰</div>
    <div class="nav-list">
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="#methodology">Methodology</a></li>
        <li><a href="#members">Members</a></li>
        <li><a href="#supervisor">Supervisor</a></li>

      </ul>
    </div>
  </div>
</header>

<!-- Info -->
<section id="info" class="dyslexia-section">
  <div class="container">
    <h2 class="section-title"><span>About</span> Dyslexia</h2>

    <div class="info-paragraph">
      <p>
        Dyslexia is a learning disorder that affects a person's ability to read, write, and process language. Many children with dyslexia go undiagnosed for years, often leading to difficulties in education and self-esteem. Traditional diagnostic methods are time-consuming, subjective, and often limited to a single mode of assessment.
      </p>
      <p>
        To address these challenges, our research introduces an innovative mobile application designed to detect dyslexia at an early stage using a multimodal approach. Our solution analyzes three key indicators: handwriting patterns, eye movement during reading, and audio recordings of reading behavior. By combining these data sources, we provide a more accurate and comprehensive assessment of dyslexia risk.
      </p>
      <p>
        Unlike existing systems that often rely on isolated data or require clinical environments, our platform is mobile, accessible, and designed for use in real-world settings like schools and therapy centers. It offers real-time feedback, personalized reports, and actionable insights to support educators, clinicians, and parents in making timely interventions.
      </p>
      <p>
        To address the limitations of traditional dyslexia assessments, our research introduces a multimodal mobile application that analyzes three key behavioral indicators: handwriting, eye movement, and oral reading patterns. Each of these modalities reflects distinct cognitive and linguistic challenges faced by individuals with dyslexia.
      </p>
      <p>
        Rather than relying on a single test or clinical observation, our approach uses machine learning-driven analysis across these diverse input types to deliver a more holistic and accurate evaluation. By doing so, we reduce subjectivity, support real-time screening, and increase accessibility,especially in under-resourced environments such as rural schools.
      </p>
      <p>
        Our platform is designed with:
       <ul style="list-style: none; padding-left: 0;">
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Interactive reading/writing tasks guided through the mobile interface</li>
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Real-time processing of input via camera and microphone</li>
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Personalized reporting to help educators and parents understand risk levels</li>
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Offline capabilities, ensuring reliable access in low-connectivity areas</li>
</ul>

      </p>
      <p>
        Unlike traditional diagnostic systems that require expert administration, our app empowers non-specialists to screen for dyslexia at scale,potentially transforming early intervention and support pathways.
      </p>
      <p>
        We envision this platform as a foundation for future educational tools that support personalized learning for neurodiverse students. Planned features include multilingual support, adaptive learning integration, and longitudinal tracking for continuous monitoring.
      </p>
    </div>

    <a href="index.html" class="btn-back">← Go Back</a>
  </div>
</section>

  <!-- Info -->
  <!--<section id="info">
    <div class="container">
      <h2 class="section-title"><span>About</span> Dyslexia</h2>
              <p>
                
          
Dyslexia is a learning disorder that affects a person's ability to read, write, and process language. Many children with dyslexia go undiagnosed for years, often leading to difficulties in education and self-esteem. Traditional diagnostic methods are time-consuming, subjective, and often limited to a single mode of assessment.

To address these challenges, our research introduces an innovative mobile application designed to detect dyslexia at an early stage using a multimodal approach. Our solution analyzes three key indicators: handwriting patterns, eye movement during reading, and audio recordings of reading behavior. By combining these data sources, we provide a more accurate and comprehensive assessment of dyslexia risk.

Unlike existing systems that often rely on isolated data or require clinical environments, our platform is mobile, accessible, and designed for use in real-world settings like schools and therapy centers. It offers real-time feedback, personalized reports, and actionable insights to support educators, clinicians, and parents in making timely interventions.

Our goal is to make early dyslexia detection more accurate, inclusive, and accessible, helping every child get the support they deserve.

</p>

<p>
  To address the limitations of traditional dyslexia assessments, our research introduces a multimodal mobile application that analyzes three key behavioral indicators: handwriting, eye movement, and oral reading patterns. Each of these modalities reflects distinct cognitive and linguistic challenges faced by individuals with dyslexia.

Rather than relying on a single test or clinical observation, our approach uses machine learning-driven analysis across these diverse input types to deliver a more holistic and accurate evaluation. By doing so, we reduce subjectivity, support real-time screening, and increase accessibility—especially in under-resourced environments such as rural schools.

Our platform is designed with:

Interactive reading/writing tasks guided through the mobile interface

Real-time processing of input via camera and microphone

Personalized reporting to help educators and parents understand risk levels

Offline capabilities, ensuring reliable access in low-connectivity areas

Unlike traditional diagnostic systems that require expert administration, our app empowers non-specialists to screen for dyslexia at scale—potentially transforming early intervention and support pathways.

We envision this platform as a foundation for future educational tools that support personalized learning for neurodiverse students. Planned features include multilingual support, adaptive learning integration, and longitudinal tracking for continuous monitoring.
</p>
<a href="index.html" class="btn-back">← Go Back</a>
    </div>
  </section>-->

  <!-- Methodology -->
  <section id="methodology">
    <div class="container">
      <h2 class="section-title"><span>Our</span> Methodology</h2>
      <p>Our research aims to develop a multimodal solution to detect dyslexia early by analyzing data from various input sources like handwriting, audio-based reading patterns, and reading durations. We employ machine learning algorithms to recognize potential signs of dyslexia and generate suggestions for further assessment or intervention.</p>
     <div class="dyslexia-section">

      <p>

        <p>
  <strong>Dyslexia</strong> is a learning disorder that affects a person's ability to read, write, and process language. Many children with dyslexia go undiagnosed for years, leading to difficulties in education and self-esteem. Traditional diagnostic methods are time-consuming, subjective, and often limited to a single mode of assessment.
</p>

<p>
  To address these challenges, our research introduces an innovative mobile application designed to detect dyslexia at an early stage using a <strong>multimodal approach</strong>. Our solution analyzes three key indicators:
</p>

<ul style="list-style: none; padding-left: 0;">
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Handwriting patterns</li>
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Eye movement during reading</li>
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Audio recordings of reading behavior</li>
</ul>


<p>
  By combining these data sources, we provide a more accurate and comprehensive assessment of dyslexia risk. Unlike systems that rely on isolated data, our Application is:
</p>

<ul style="list-style: none; padding-left: 0;">
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Mobility and accessible</li>
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Real-time with feedback with reports</li>
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Designed for schools or clinic centre (users)</li>
</ul>

<p>
  Our goal is to make early dyslexia detection <strong>more accurate, inclusive, and accessible</strong>, helping every child get the support they deserve.
</p>


<p>
  Rather than relying on a single test, our application uses <strong>machine learning</strong> to analyze diverse behavioral indicators. This reduces subjectivity and improves screening, especially in under-resourced environments.
</p>

<ul style="list-style: none; padding-left: 0;">
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Interactive tasks guided through the app</li>
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Real-time processing via camera & microphone</li>
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Report Generation</li>
</ul>


<p>
  Non-specialists can now screen for dyslexia at scale. Future features will include:
</p>

<ul style="list-style: none; padding-left: 0;">
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Multilingual support</li>
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Adaptive learning integration</li>
  <li><span style="color: #7629ad; font-weight: bold;">&#10004;</span> Long-term progress tracking</li>
</ul>

<p>
  This platform lays the foundation for <strong>personalized education</strong> tools that support neurodiverse learners from early on.
</p>
</div>
      </p>
      <div class="diagram">
        <h3>System Architecture Diagram</h3>
        <img src="./img/Architecture.png"/>
      </div>
    </div>
  </section>

  <!-- Research Members -->
  <section id="members">
    <div class="container">
      <h2 class="section-title"><span>Research</span> Members</h2>
      <div class="members-grid">
        <div class="member-box">
        <img src="./img/Rushdha.png"/>
          <ul>
    <li class="member-name"><strong>M.Y.F. Rustha</strong></li>
    <li>ICT/20/920</li>
    <li>ict20920@fot.sjp.ac.lk</li>
    <li>0760401112</li>
    <li>Software Technology</li>
          </ul>
        </div>
        <div class="member-box">
        <img src="./img/Faazath.jpg"/>
          <ul>
             <li class="member-name"><strong>Z.M.F.Faazath</strong></li>
    <li>ICT/20/839</li>
    <li>ict20839@fot.sjp.ac.lk</li>
    <li>0763625246</li>
    <li>Software Technology</li>
          </ul>
        </div>
        <div class="member-box">
        <img src="./img/Nuzha.png"/>
        <ul>
          <li class="member-name"><strong>M.W.W.Nuzha</strong></li>
    <li>ICT/20/898</li>
    <li>ict20898@fot.sjp.ac.lk</li>
    <li>0770503263</li>
    <li>Software Technology</li>
    </ul>
        </div>
      </div>
    </div>
  </section>

  <!-- Supervisor -->
  <!-- Supervisor -->
<section id="supervisor">
  <div class="supervisor-container">
    <h2 class="section-title"><span>Research</span> Supervisor</h2>
    <div class="supervisor-box">
      <img src="./img/supervisor.jpg" alt="Supervisor Photo" />
      <p>
        <strong class="supervisor-name">Dr. Nalaka Lankasena</strong><br>
        <span class="supervisor-details">
          Senior Lecturer<br>
          Department of Information Communication Technology<br>
          Faculty of Technology<br>
          University of Sri Jayewardenepura
        </span>
      </p>
    </div>
  </div>
  
 
</section>
<footer id="footer" style="background: linear-gradient(135deg, #6f2486, #fefeff); color: white; padding: 12px 2;">
  <div class="footer-container" style="text-align: center;">
    <div class="footer-content">
      <div class="footer-copyright">
        <p>&copy; 2025 Research Team (Scholarly). All rights reserved | 
                    <a href="privacy policy.html" style="color: rgb(6, 2, 2); text-decoration: underline;">Privacy Policy</a>



        </p>
      </div>
    </div>
  </div>
</footer>


  <!-- End Footer -->
  <!-- Mobile Nav Toggle JS -->
  <script>
    const hamburger = document.querySelector(".hamburger");
    const navList = document.querySelector(".nav-list ul");

    hamburger.addEventListener("click", () => {
      navList.classList.toggle("active");
      hamburger.classList.toggle("active");
    });
  </script>

</body>
</html>
